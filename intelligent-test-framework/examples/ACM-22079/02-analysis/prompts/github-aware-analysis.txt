You are conducting a comprehensive analysis of JIRA ticket {JIRA_TICKET} with full access to the stolostron GitHub organization and related repositories. Your task is to perform real-time code analysis and generate implementation-ready test specifications.

## DYNAMIC REPOSITORY ACCESS CAPABILITIES

You have access to:
- **Direct API Access**: Any file from any stolostron repository via GitHub API
- **Real-Time PRs**: Current pull requests and their complete diffs
- **Recent Changes**: Latest commits, branches, and repository activity
- **Cross-Repository Analysis**: Pattern discovery across multiple repositories
- **Live Code Review**: Current implementation state, not static snapshots

## REPOSITORIES TO ANALYZE

Primary repositories for this analysis:
{DETECTED_REPOSITORIES}

## ANALYSIS METHODOLOGY

### 1. REAL-TIME CODE EXAMINATION
For each relevant repository:
- Examine current main/master branch state
- Identify files directly related to {JIRA_TICKET}
- Analyze recent commits that mention related keywords
- Review any open/recent PRs that implement related functionality

Use these approaches:
```
# Direct file access examples:
"Show me the current implementation of pkg/jobs/hive/hive.go from stolostron/cluster-curator-controller"
"Analyze the upgrade logic in the latest version of cmd/curator/curator.go"
"Compare error handling patterns across stolostron/clc-ui-e2e test files"
```

### 2. PR AND COMMIT ANALYSIS
- Search for PRs containing keywords: digest, upgrade, curator, {JIRA_TICKET}
- Analyze implementation patterns in recent relevant commits
- Identify breaking changes or new APIs introduced
- Review test patterns in related PRs

### 3. CROSS-REPOSITORY PATTERN DISCOVERY
Analyze patterns across:
- **Backend (cluster-curator-controller)**: Go implementation, APIs, validation logic
- **Frontend (console)**: React components, UI workflows, error handling
- **Testing (clc-ui-e2e)**: Cypress tests, test patterns, validation approaches
- **Integration**: How changes propagate across the entire stack

### 4. FEATURE IMPLEMENTATION ANALYSIS

For {JIRA_TICKET}, specifically analyze:

#### Backend Implementation (cluster-curator-controller)
- **Digest Resolution Logic**: How image digests are resolved vs tags
- **Upgrade Validation**: Validation logic for non-recommended upgrades
- **Error Handling**: How failed digest resolution is handled
- **API Changes**: Any new fields, endpoints, or behaviors
- **Configuration**: New configuration options or environment variables

#### UI Integration (console/clc-ui-e2e)
- **UI Components**: Forms, inputs, validation messages for digest-based upgrades
- **User Workflows**: How users configure and trigger digest-based upgrades
- **Error Display**: How errors and warnings are presented to users
- **Test Coverage**: Existing test patterns that validate upgrade scenarios

#### Test Patterns Analysis
- **Unit Tests**: Backend validation and logic testing approaches
- **Integration Tests**: API and component integration testing
- **E2E Tests**: Complete user workflow validation
- **Error Scenarios**: How edge cases and failures are tested

## ANALYSIS OUTPUT REQUIREMENTS

Generate a comprehensive analysis including:

### 1. FEATURE IMPLEMENTATION SUMMARY
- **What Changed**: Detailed description of the implementation
- **How It Works**: Technical explanation of the digest-based upgrade flow
- **Key Components**: Primary files, functions, and UI components involved
- **Dependencies**: External systems, APIs, or libraries required

### 2. REPOSITORY-SPECIFIC INSIGHTS
For each analyzed repository:
- **Primary Changes**: Key modifications related to the feature
- **Integration Points**: How this repository connects to others
- **Test Requirements**: What testing approaches are needed
- **Risk Areas**: Potential failure points or edge cases

### 3. COMPREHENSIVE TEST STRATEGY
Based on real code analysis:
- **Unit Test Requirements**: Specific functions and logic to test
- **Integration Test Scenarios**: Component interaction validation
- **E2E Test Workflows**: Complete user journey testing
- **Error Testing**: Comprehensive error scenario coverage
- **Performance Testing**: Load and performance considerations

### 4. IMPLEMENTATION RECOMMENDATIONS
- **Test Architecture**: How tests should be structured
- **Framework Choices**: Best testing frameworks for different scenarios
- **Automation Strategy**: CI/CD integration and automation approaches
- **Quality Gates**: Code review and validation checkpoints

## ENHANCED ANALYSIS INSTRUCTIONS

### Real-Time Code Review
1. **Current State Analysis**: Examine the actual current implementation
2. **Recent Evolution**: Understand how the feature has evolved recently
3. **Active Development**: Identify ongoing changes or planned improvements
4. **Community Feedback**: Review recent issues, discussions, or feedback

### Dynamic Pattern Recognition
1. **Cross-Repository Consistency**: Ensure test patterns align with existing approaches
2. **Evolution Tracking**: Understand how testing approaches have evolved
3. **Best Practice Identification**: Extract proven patterns from successful implementations
4. **Innovation Opportunities**: Identify areas for testing methodology improvements

### Quality Assurance Focus
1. **Coverage Gaps**: Identify areas where additional testing is needed
2. **Risk Mitigation**: Address high-risk scenarios with comprehensive testing
3. **User Experience**: Ensure tests validate real user workflows
4. **Maintenance**: Design tests that are maintainable and robust

Remember: You have full access to live repositories. Don't rely on assumptions - examine the actual current code, recent changes, and active development to provide the most accurate and current analysis possible.

## OUTPUT FORMAT

Structure your analysis as:

1. **EXECUTIVE SUMMARY** (2-3 paragraphs)
2. **REPOSITORY ANALYSIS** (detailed findings per repository)
3. **FEATURE IMPLEMENTATION DETAILS** (technical deep dive)
4. **COMPREHENSIVE TEST STRATEGY** (testing approach and requirements)
5. **IMPLEMENTATION ROADMAP** (step-by-step testing implementation plan)
6. **QUALITY ASSURANCE RECOMMENDATIONS** (best practices and guidelines)

Begin your analysis by examining the current state of the primary repositories and identifying the most recent relevant changes.