# Test Plan for ACM-22079: Support digest-based upgrades via ClusterCurator

## Setup and Prerequisites
- ACM hub cluster with ClusterCurator operator v2.9+ installed and running
- At least one managed OpenShift cluster (4.12+) imported into ACM hub with healthy status
- Test user with cluster-admin permissions on hub cluster and cluster-curator RBAC on managed clusters
- Target managed cluster must have available updates in its update graph via `oc adm upgrade` command
- Network connectivity for digest resolution from quay.io/openshift-release-dev registry
- Cincinnati update service accessible for release metadata retrieval

### Test Case 1: Digest-Based Upgrade Success Scenarios
**Description**: Validates that ClusterCurator can successfully discover and use digest-based images for upgrades when the force annotation is present, and falls back to availableUpdates when conditionalUpdates are not available.

**Setup**: 
- Managed cluster must be in Available state with established update channels
- Target upgrade version should exist in either conditionalUpdates or availableUpdates arrays
- Verify managed cluster has update recommendations available via `oc get clusterversion -o yaml`

| Test Steps | Expected Results |
|------------|------------------|
| 1. Log into ACM hub cluster and verify ClusterCurator operator status<br/>CLI: `oc login https://api.hub-cluster.example.com:6443 -u testuser`<br/>`oc get pods -n open-cluster-management-hub | grep cluster-curator`<br/>UI: Navigate to ACM Console → Login with credentials | CLI verification: `Login successful. You have access to X projects...` and cluster-curator pod shows `Running` status<br/>UI verification: ACM Console dashboard loads successfully showing cluster count and health status |
| 2. Create test namespace for organized testing and label for identification<br/>CLI: `oc create namespace digest-upgrade-test`<br/>`oc label namespace digest-upgrade-test test-type=digest-upgrade`<br/>UI: N/A | CLI verification: `namespace/digest-upgrade-test created` and label applied successfully<br/>UI verification: N/A |
| 3. Verify target managed cluster current version and available updates<br/>CLI: `oc get managedcluster <cluster-name> -o jsonpath='{.status.version.kubernetes}'`<br/>`oc get clusterversion --context=<managed-cluster> -o jsonpath='{.status.availableUpdates[*].version}'`<br/>UI: Cluster management → Clusters → Select cluster → Overview tab | CLI verification: Shows current version (e.g., `4.14.15`) and available update versions listed<br/>UI verification: Cluster details show current version and available updates in UI |
| 4. Apply ClusterCurator with force annotation for digest support<br/>CLI: Create file with YAML below and apply with `oc apply -f clustercurator.yaml`<br/>```yaml<br/>apiVersion: cluster.open-cluster-management.io/v1beta1<br/>kind: ClusterCurator<br/>metadata:<br/>  name: digest-upgrade-test<br/>  namespace: <managed-cluster-namespace><br/>  annotations:<br/>    cluster.open-cluster-management.io/upgrade-allow-not-recommended-versions: "true"<br/>spec:<br/>  desiredCuration: upgrade<br/>  upgrade:<br/>    desiredUpdate: "4.15.10"<br/>    channel: "stable-4.15"<br/>```<br/>UI: Cluster lifecycle → Curators → Create ClusterCurator | CLI verification: `clustercurator.cluster.open-cluster-management.io/digest-upgrade-test created` and resource in `pending` phase<br/>UI verification: New curator appears in Curators list with pending status and correct target version |
| 5. Verify force annotation enables digest discovery logic<br/>CLI: `oc get clustercurator digest-upgrade-test -n <managed-cluster-namespace> -o jsonpath='{.metadata.annotations.cluster\.open-cluster-management\.io/upgrade-allow-not-recommended-versions}'`<br/>UI: Cluster lifecycle → Curators → digest-upgrade-test → Details → Annotations | CLI verification: Output shows exactly `"true"` confirming annotation properly parsed<br/>UI verification: Annotation `cluster.open-cluster-management.io/upgrade-allow-not-recommended-versions: "true"` visible in resource details |
| 6. Monitor ManagedClusterView creation and ClusterVersion retrieval<br/>CLI: `oc get managedclusterview -n <managed-cluster-namespace> --watch`<br/>`oc get managedclusterview -n <managed-cluster-namespace> -l cluster-curator-name=digest-upgrade-test`<br/>UI: Search → Kind: ManagedClusterView → Filter by namespace | CLI verification: New ManagedClusterView appears within 30 seconds with naming pattern `digest-upgrade-test-cv-<hash>`<br/>UI verification: ManagedClusterView resource visible with successful sync status and populated result field |
| 7. Verify digest extraction from conditionalUpdates in ClusterVersion<br/>CLI: `oc get managedclusterview -n <managed-cluster-namespace> -l cluster-curator-name=digest-upgrade-test -o jsonpath='{.items[0].status.result.status.conditionalUpdates[?(@.version=="4.15.10")].image}'`<br/>UI: Search results → Select ManagedClusterView → View YAML → Status.result.status.conditionalUpdates | CLI verification: Returns digest format exactly like `quay.io/openshift-release-dev/ocp-release@sha256:abc123def456...` (64-char hash)<br/>UI verification: Image field shows digest format in conditionalUpdates array with matching version |
| 8. Confirm ManagedClusterAction uses digest without force flag<br/>CLI: `oc get managedclusteraction -n <managed-cluster-namespace> -l cluster-curator-name=digest-upgrade-test -o yaml | grep -A10 -B5 "desiredUpdate"`<br/>UI: Search → Kind: ManagedClusterAction → View latest action → Spec section | CLI verification: Shows `image: quay.io/openshift-release-dev/ocp-release@sha256:...` with NO `force: true` flag present<br/>UI verification: Action spec.actionRequest shows digest image format without force parameter indicating digest-based upgrade |

### Test Case 2: Tag-Based Fallback and Error Handling  
**Description**: Tests the fallback mechanism when digest discovery fails and validates proper error handling for invalid upgrade targets.

**Setup**:
- Use managed cluster where target version may not be in conditionalUpdates but exists in availableUpdates
- Prepare test scenarios with invalid version formats for comprehensive error testing
- Ensure network access to verify tag-based fallback behavior and error propagation

| Test Steps | Expected Results |
|------------|------------------|
| 1. Create ClusterCurator targeting version likely in availableUpdates only<br/>CLI: `oc apply -f clustercurator-fallback.yaml` with `desiredUpdate: "4.14.25"` and same force annotation<br/>UI: Create new ClusterCurator with older target version in availableUpdates | CLI verification: `clustercurator.cluster.open-cluster-management.io/digest-fallback-test created` successfully<br/>UI verification: Resource appears in Curators list with pending status targeting older version |
| 2. Verify digest discovery attempts conditionalUpdates first<br/>CLI: `oc get managedclusterview -n <managed-cluster-namespace> -l cluster-curator-name=digest-fallback-test -o jsonpath='{.status.result.status.conditionalUpdates[?(@.version=="4.14.25")]}'`<br/>UI: Check ManagedClusterView status conditionalUpdates array | CLI verification: Returns empty `[]` or null indicating version not in conditionalUpdates<br/>UI verification: ConditionalUpdates array does not contain target version 4.14.25 |
| 3. Confirm fallback to availableUpdates when conditionalUpdates insufficient<br/>CLI: `oc get managedclusterview -n <managed-cluster-namespace> -l cluster-curator-name=digest-fallback-test -o jsonpath='{.status.result.status.availableUpdates[?(@.version=="4.14.25")].image}'`<br/>UI: Check ManagedClusterView status availableUpdates array | CLI verification: Returns digest format `quay.io/openshift-release-dev/ocp-release@sha256:...` extracted from availableUpdates<br/>UI verification: AvailableUpdates array contains target version with digest image |
| 4. Test upgrade with version having no digest available anywhere<br/>CLI: `oc apply -f clustercurator-nodgest.yaml` with `desiredUpdate: "4.14.99"` (non-existent version)<br/>UI: N/A | CLI verification: ClusterCurator created successfully but will demonstrate tag fallback behavior<br/>UI verification: N/A |
| 5. Monitor tag-based fallback in ManagedClusterAction when digest unavailable<br/>CLI: `oc get managedclusteraction -n <managed-cluster-namespace> -l cluster-curator-name=clustercurator-nodigest -o yaml | grep -A10 -B5 "force\|desiredUpdate"`<br/>UI: View ManagedClusterAction details for tag-based action | CLI verification: Shows tag format `quay.io/openshift-release-dev/ocp-release:4.14.99-multi` AND `force: true` present<br/>UI verification: Action shows tag-based image with force parameter enabled indicating fallback occurred |
| 6. Create ClusterCurator WITHOUT force annotation to verify standard behavior<br/>CLI: `oc apply -f clustercurator-standard.yaml` (remove annotation line entirely)<br/>UI: Create ClusterCurator with standard configuration omitting force annotation | CLI verification: ClusterCurator created successfully without special annotations<br/>UI verification: Resource created with standard upgrade configuration visible in UI |
| 7. Verify standard upgrade behavior bypasses digest discovery entirely<br/>CLI: `oc get managedclusteraction -n <managed-cluster-namespace> -l cluster-curator-name=clustercurator-standard -o yaml | grep -A5 -B5 "force\|image"`<br/>UI: Check action parameters for standard behavior | CLI verification: Shows `force: true` with tag format `quay.io/openshift-release-dev/ocp-release:4.15.10-multi` (standard behavior)<br/>UI verification: Action uses standard tag-based upgrade parameters without digest discovery |
| 8. Test comprehensive error handling with invalid version format<br/>CLI: `oc apply -f clustercurator-invalid.yaml` with `desiredUpdate: "invalid.version.format"`<br/>UI: N/A | CLI verification: ClusterCurator created but upgrade fails with validation error in status conditions<br/>UI verification: N/A |
| 9. Check detailed error messages and status conditions<br/>CLI: `oc get clustercurator -n <managed-cluster-namespace> -o jsonpath='{.items[*].status.conditions[?(@.type=="Failed")].message}'`<br/>`oc describe clustercurator <invalid-curator-name> -n <managed-cluster-namespace>`<br/>UI: View ClusterCurator status conditions and events | CLI verification: Clear error message like `invalid version format: invalid.version.format does not match semantic versioning`<br/>UI verification: Error condition visible in resource status with helpful troubleshooting information |

### Test Case 3: Multi-Cluster and RBAC Validation
**Description**: Validates digest-based upgrades work correctly across multiple managed clusters simultaneously and verifies proper RBAC behavior for different user permission levels.

**Setup**:
- Multiple managed clusters (minimum 2) imported into ACM hub with different OpenShift versions
- Test service account with limited ClusterCurator permissions for RBAC validation
- RBAC policies configured with ClusterRole and RoleBinding to test permission boundaries

| Test Steps | Expected Results |
|------------|------------------|
| 1. Verify multiple managed clusters available with different versions<br/>CLI: `oc get managedcluster -o custom-columns=NAME:.metadata.name,STATUS:.status.conditions[0].type,VERSION:.status.version.kubernetes`<br/>UI: Cluster management → Clusters → Filter by Available status | CLI verification: Shows 2+ clusters in Available state with different Kubernetes versions (e.g., 4.14.15, 4.15.8)<br/>UI verification: Multiple clusters visible with Available status and version information displayed |
| 2. Create concurrent ClusterCurator resources targeting different clusters<br/>CLI: `oc apply -f clustercurator-cluster1.yaml -f clustercurator-cluster2.yaml` (different namespaces: cluster1, cluster2)<br/>UI: Create multiple ClusterCurators targeting different managed clusters | CLI verification: Both ClusterCurators created successfully: `clustercurator.cluster.open-cluster-management.io/multi-test-1 created`<br/>UI verification: Multiple curators appear in list with different target clusters and pending status |
| 3. Monitor independent digest discovery and resource isolation<br/>CLI: `oc get managedclusterview -A | grep -E "(cluster1|cluster2)" | grep digest`<br/>`oc get managedclusterview -n cluster1 -o name && oc get managedclusterview -n cluster2 -o name`<br/>UI: Search across all namespaces for ManagedClusterViews | CLI verification: Each cluster namespace has separate ManagedClusterView resources with unique names<br/>UI verification: Views show correct cluster targeting without namespace conflicts or resource overlap |
| 4. Verify no cross-cluster resource interference or data leakage<br/>CLI: `oc get managedclusteraction -A -o custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name,TARGET:.spec.actionRequest.object.metadata.name,IMAGE:.spec.actionRequest.object.spec.update.image`<br/>UI: View all ManagedClusterActions across namespaces for cross-contamination | CLI verification: Each action correctly scoped to intended cluster with appropriate digest/tag for that cluster version<br/>UI verification: Actions properly isolated to intended managed clusters without cross-cluster data mixing |
| 5. Create test service account with limited ClusterCurator permissions<br/>CLI: `oc create serviceaccount clustercurator-test -n default`<br/>`oc create clusterrole clustercurator-limited --verb=get,list,create,update,patch --resource=clustercurators`<br/>`oc create clusterrolebinding clustercurator-test-binding --clusterrole=clustercurator-limited --serviceaccount=default:clustercurator-test`<br/>UI: N/A | CLI verification: Service account, ClusterRole, and ClusterRoleBinding created successfully with appropriate RBAC scope<br/>UI verification: N/A |
| 6. Test ClusterCurator creation with limited service account permissions<br/>CLI: `oc create -f clustercurator-rbac-test.yaml --as=system:serviceaccount:default:clustercurator-test`<br/>`oc auth can-i create managedclusteractions --as=system:serviceaccount:default:clustercurator-test`<br/>UI: N/A | CLI verification: ClusterCurator created successfully, `auth can-i` returns `no` for ManagedClusterAction (controller creates these)<br/>UI verification: N/A |
| 7. Verify controller creates ManagedClusterAction with proper ownership and permissions<br/>CLI: `oc get managedclusteraction -n <target-cluster-namespace> -o jsonpath='{.items[0].metadata.ownerReferences[0]}' | jq .`<br/>`oc get managedclusteraction -n <target-cluster-namespace> -o jsonpath='{.items[0].metadata.creationTimestamp}'`<br/>UI: Check ManagedClusterAction owner references and metadata | CLI verification: Owner reference shows `{"kind":"ClusterCurator","name":"<curator-name>","controller":true}`, not test user<br/>UI verification: Owner reference correctly points to ClusterCurator resource with controller ownership |
| 8. Test concurrent upgrade operations and resource cleanup<br/>CLI: `oc get clustercurator -A --watch` (monitor progress)<br/>`oc delete clustercurator --all -A --wait=true`<br/>`oc delete namespace digest-upgrade-test cluster1 cluster2`<br/>UI: Monitor multiple curator progress then delete resources | CLI verification: All resources deleted cleanly without errors, no orphaned ManagedClusterActions or Views remain<br/>UI verification: Resources removed from UI listings, no dangling references in cluster management view |
| 9. Verify RBAC audit trail and permission enforcement<br/>CLI: `oc get events -A | grep clustercurator-test | head -5`<br/>`oc auth can-i --list --as=system:serviceaccount:default:clustercurator-test | grep cluster`<br/>UI: N/A | CLI verification: Events show service account actions, permissions limited to clustercurator resources only<br/>UI verification: N/A |

VALIDATION REQUIREMENTS:
✅ All oc commands include complete syntax with proper namespace targeting
✅ Expected results specify exact output formats and values for verification
✅ Edge cases covered including error conditions and fallback scenarios  
✅ Environment setup includes version requirements and network dependencies
✅ Comprehensive cleanup steps ensure no resource leakage between test runs
✅ RBAC testing validates security model and permission boundaries
✅ Multi-cluster scenarios test concurrent operations and resource isolation
