#!/usr/bin/env python3
"""
Version Intelligence Service - Phase 0 Implementation
Traditional Python implementation for reliable foundation context creation
"""

import os
import json
import re
import logging
from typing import Dict, Any, Optional, Tuple, List
from datetime import datetime
from pathlib import Path

from foundation_context import (
    FoundationContext, 
    FoundationContextBuilder, 
    create_foundation_context,
    ContextValidationLevel
)

from jira_api_client import JiraApiClient, JiraApiError, JiraTicketData
from environment_assessment_client import EnvironmentAssessmentClient, EnvironmentAssessmentError, EnvironmentData


# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class JIRAExtractionError(Exception):
    """Raised when JIRA extraction fails - stops framework completely"""
    
    def __init__(self, message: str, jira_id: str, suggestions: List[str]):
        self.message = message
        self.jira_id = jira_id
        self.suggestions = suggestions
        super().__init__(self.message)
    
    def get_failure_report(self) -> Dict[str, Any]:
        """Generate comprehensive failure report with actionable suggestions"""
        return {
            'error': f'JIRA extraction failed for {self.jira_id}',
            'details': self.message,
            'timestamp': datetime.now().isoformat(),
            'actionable_suggestions': self.suggestions,
            'next_steps': [
                'Fix the JIRA connectivity issues listed above',
                'Verify JIRA ticket exists and is accessible',
                'Re-run the framework after resolving issues'
            ],
            'framework_action': 'STOPPED - Framework cannot proceed without JIRA data'
        }


class VersionIntelligenceError(Exception):
    """Custom exception for Version Intelligence Service"""
    pass


class JiraIntegrationError(VersionIntelligenceError):
    """JIRA API integration errors"""
    pass


class EnvironmentAssessmentError(VersionIntelligenceError):
    """Environment assessment errors"""
    pass


class VersionIntelligenceService:
    """
    Traditional Python implementation for reliable Phase 0 foundation
    Provides deterministic JIRA analysis, version gap assessment, and foundation context creation
    """
    
    def __init__(self, framework_root: str = None, universal_tool_access: bool = True):
        self.framework_root = framework_root or os.getcwd()
        self.runs_dir = os.path.join(self.framework_root, "runs")
        self.config = self._load_configuration()
        self.universal_tool_access = universal_tool_access
        
        # Initialize components with universal tool access
        self.jira_integration = self._initialize_jira_client()
        self.environment_assessor = self._initialize_environment_client()
        
        if self.universal_tool_access:
            logger.info("🌍 Version Intelligence Service initialized with universal tool access enabled")
        
        logger.info(f"Version Intelligence Service initialized at {self.framework_root}")
    
    def execute_any_tool(self, tool: str, args: List[str], timeout: int = 30) -> Dict[str, Any]:
        """
        Universal tool execution at Phase 0 level - enables ANY tool ANYWHERE
        Delegates to environment assessor for consistent tool management
        """
        if not self.universal_tool_access:
            raise VersionIntelligenceError(f"Universal tool access disabled - cannot execute {tool}")
        
        if self.environment_assessor:
            return self.environment_assessor.execute_any_tool(tool, args, timeout)
        else:
            # Fallback direct execution if environment assessor unavailable
            logger.warning("Environment assessor unavailable, executing tool directly")
            try:
                import subprocess
                result = subprocess.run(
                    [tool] + args,
                    capture_output=True,
                    text=True,
                    timeout=timeout
                )
                return {
                    'tool': tool,
                    'args': args,
                    'returncode': result.returncode,
                    'stdout': result.stdout,
                    'stderr': result.stderr,
                    'success': result.returncode == 0,
                    'execution_timestamp': datetime.now().isoformat(),
                    'fallback_execution': True
                }
            except Exception as e:
                return {
                    'tool': tool,
                    'args': args,
                    'returncode': -1,
                    'stdout': '',
                    'stderr': str(e),
                    'success': False,
                    'execution_timestamp': datetime.now().isoformat(),
                    'error': 'fallback_execution_failed'
                }
    
    def _initialize_jira_client(self) -> Optional[JiraApiClient]:
        """Initialize JIRA API client with proper error handling"""
        try:
            jira_client = JiraApiClient()
            connected, status_msg = jira_client.test_connection()
            
            if connected:
                logger.info(f"JIRA API client connected successfully: {status_msg}")
            else:
                logger.warning(f"JIRA API connection failed: {status_msg}")
                logger.info("Will use fallback simulation for JIRA data")
            
            return jira_client
            
        except Exception as e:
            logger.warning(f"Failed to initialize JIRA client: {e}")
            logger.info("Will use fallback simulation for JIRA data")
            return None
    
    def _initialize_environment_client(self) -> Optional[EnvironmentAssessmentClient]:
        """Initialize environment assessment client with universal tool access"""
        try:
            from environment_assessment_client import EnvironmentAssessmentConfig
            
            # Create config with universal tool access
            config = EnvironmentAssessmentConfig(universal_tool_access=self.universal_tool_access)
            env_client = EnvironmentAssessmentClient(config)
            connected, status_msg = env_client.test_connectivity()
            
            if connected:
                logger.info(f"Environment assessment client connected successfully: {status_msg}")
            else:
                logger.warning(f"Environment assessment connection failed: {status_msg}")
                logger.info("Will use fallback simulation for environment data")
            
            return env_client
            
        except Exception as e:
            logger.warning(f"Failed to initialize environment client: {e}")
            logger.info("Will use fallback simulation for environment data")
            return None
    
    def _load_configuration(self) -> Dict[str, Any]:
        """Load service configuration"""
        return {
            'version_detection_patterns': [
                r'(\d+\.\d+\.\d+)',  # Semantic versioning
                r'v(\d+\.\d+\.\d+)',  # Version with v prefix
                r'(\d+\.\d+)',  # Major.minor
            ],
            'supported_platforms': ['kubernetes', 'openshift', 'rancher'],
            'default_environment_timeout': 30,
            'context_validation_level': ContextValidationLevel.STANDARD
        }
    
    def analyze_version_gap(self, jira_id: str, environment: str = None) -> FoundationContext:
        """
        Main entry point for Phase 0 analysis
        Analyzes JIRA ticket and environment to create foundation context
        """
        logger.info(f"Starting version gap analysis for {jira_id}")
        
        try:
            # Step 1: Extract JIRA information
            jira_data = self._extract_jira_information(jira_id)
            logger.info(f"JIRA data extracted: {jira_data['title'][:50]}...")
            
            # Step 2: Determine target version from JIRA
            target_version = self._determine_target_version(jira_data)
            logger.info(f"Target version identified: {target_version}")
            
            # Step 3: Assess environment version
            environment_data = self._assess_environment_version(environment)
            logger.info(f"Environment version detected: {environment_data['version']}")
            
            # Step 4: Calculate version gap with enhanced product context
            version_gap_analysis = self._calculate_version_gap(target_version, environment_data)
            logger.info(f"Version gap analysis: {version_gap_analysis['comparison']}")
            
            # Step 5: Generate deployment instruction
            deployment_instruction = self._generate_deployment_instruction(
                target_version, environment_data['version'], version_gap_analysis
            )
            
            # Step 6: Create foundation context
            foundation_context = self._build_foundation_context(
                jira_data, target_version, environment_data, 
                version_gap_analysis, deployment_instruction
            )
            
            # Step 7: Validate and finalize
            if foundation_context.is_ready_for_agent_inheritance():
                logger.info("✅ Foundation context ready for agent inheritance")
                return foundation_context
            else:
                raise VersionIntelligenceError(
                    f"Foundation context validation failed: {foundation_context.validation_results}"
                )
                
        except Exception as e:
            logger.error(f"Version gap analysis failed for {jira_id}: {str(e)}")
            raise VersionIntelligenceError(f"Analysis failed: {str(e)}") from e
    
    def _extract_jira_information(self, jira_id: str) -> Dict[str, Any]:
        """Extract JIRA ticket information using API client with fallback"""
        logger.info(f"Extracting JIRA information for {jira_id}")
        
        # Try JIRA API client first if available
        if self.jira_integration:
            try:
                ticket_data = self.jira_integration.get_ticket_information(jira_id)
                logger.info(f"Successfully retrieved {jira_id} via JIRA API")
                
                # Convert JiraTicketData to legacy format for compatibility
                return {
                    'id': ticket_data.id,
                    'title': ticket_data.title,
                    'status': ticket_data.status,
                    'fix_version': ticket_data.fix_version,
                    'priority': ticket_data.priority,
                    'component': ticket_data.component,
                    'description': ticket_data.description,
                    'assignee': ticket_data.assignee,
                    'reporter': ticket_data.reporter,
                    'created': ticket_data.created,
                    'updated': ticket_data.updated,
                    'labels': ticket_data.labels,
                    'api_source': 'jira_api'
                }
                
            except JiraApiError as e:
                logger.error(f"❌ JIRA API failed for {jira_id}: {e}")
                self._raise_jira_failure(jira_id, str(e))
            except Exception as e:
                logger.error(f"❌ Unexpected error fetching {jira_id}: {e}")
                self._raise_jira_failure(jira_id, str(e))
        
        # If no JIRA integration available, raise clear error
        logger.error(f"❌ No JIRA integration available for {jira_id}")
        self._raise_jira_failure(jira_id, "No JIRA integration configured")
    
    # REMOVED: _get_enhanced_simulated_data method
    # All JIRA simulation removed - framework now raises JIRAExtractionError with actionable suggestions
    # when JIRA data cannot be retrieved, stopping framework execution completely
    
    def _guess_component_from_ticket_id(self, ticket_number: str) -> str:
        """Guess component based on ticket ID patterns (realistic ACM patterns)"""
        try:
            num = int(ticket_number)
            
            # Common ACM component number ranges (based on observation)
            if 20000 <= num <= 25000:
                return 'ClusterCurator'
            elif 15000 <= num <= 20000:
                return 'ApplicationLifecycle'
            elif 25000 <= num <= 30000:
                return 'PolicyFramework'
            elif 10000 <= num <= 15000:
                return 'MultiClusterEngine'
            elif 5000 <= num <= 10000:
                return 'Observability'
            else:
                return 'ACM'
        except ValueError:
            return 'ACM'
    
    def _determine_target_version(self, jira_data: Dict[str, Any]) -> str:
        """Determine target version from JIRA data"""
        # Priority order for version detection
        version_sources = [
            jira_data.get('fix_version'),
            jira_data.get('target_version'),
            jira_data.get('version')
        ]
        
        for version_source in version_sources:
            if version_source:
                # Validate version format
                for pattern in self.config['version_detection_patterns']:
                    match = re.search(pattern, str(version_source))
                    if match:
                        version = match.group(1)
                        logger.info(f"Target version detected from fix_version: {version}")
                        return version
        
        # Fallback: search in title and description
        text_content = f"{jira_data.get('title', '')} {jira_data.get('description', '')}"
        for pattern in self.config['version_detection_patterns']:
            matches = re.findall(pattern, text_content)
            if matches:
                version = matches[-1]  # Take the last/most specific version
                logger.info(f"Target version detected from content: {version}")
                return version
        
        # Default fallback
        default_version = "2.15.0"
        logger.warning(f"No target version detected, using default: {default_version}")
        return default_version
    
    def _assess_environment_version(self, environment: str = None) -> Dict[str, Any]:
        """Assess environment version using environment client with fallback"""
        # Default to qe6 when no environment provided (as mandated by user)
        if environment is None:
            environment = 'Console: https://console-openshift-console.apps.qe6-vmware-ibm.install.dev09.red-chesterfield.com'
            logger.info(f"No environment specified - defaulting to qe6 cluster as mandated")
        logger.info(f"Assessing environment version for: {environment}")
        
        # Try environment assessment client first if available
        if self.environment_assessor:
            try:
                env_data = self.environment_assessor.assess_environment(environment)
                logger.info(f"Successfully assessed environment via {env_data.detection_method}")
                
                # Convert EnvironmentData to enhanced format with product awareness
                env_raw_data = getattr(env_data, 'raw_data', {})
                version_info = env_raw_data.get('version_info', {})
                
                return {
                    'version': env_data.version,
                    'cluster_name': env_data.cluster_name,
                    'api_url': env_data.api_url,
                    'console_url': env_data.console_url,
                    'platform': env_data.platform,
                    'region': env_data.region,
                    'health_status': env_data.health_status,
                    'connectivity_confirmed': env_data.connectivity_confirmed,
                    'detection_method': env_data.detection_method,
                    'platform_details': env_data.platform_details,
                    'tools_available': env_data.tools_available,
                    'assessment_timestamp': env_data.assessment_timestamp,
                    'api_source': 'environment_assessment',
                    # NEW: Product awareness and enhanced version info
                    'product_detected': version_info.get('product', 'Unknown'),
                    'version_detection_method': version_info.get('detection_method', 'unknown'),
                    'acm_status': self._determine_acm_status(version_info),
                    'version_context': {
                        'is_acm': version_info.get('product') == 'ACM',
                        'is_openshift': version_info.get('product') == 'OpenShift',
                        'is_kubernetes': version_info.get('product') == 'Kubernetes',
                        'command_used': version_info.get('command_used'),
                        'raw_output': version_info.get('raw_output')
                    }
                }
                
            except EnvironmentAssessmentError as e:
                logger.warning(f"Environment assessment failed: {e}")
                logger.info(f"Falling back to simulation for environment assessment")
            except Exception as e:
                logger.error(f"Unexpected error assessing environment: {e}")
                logger.info(f"Falling back to simulation for environment assessment")
        
        # AI Services fallback when environment assessment fails
        logger.info(f"Attempting AI services fallback for environment assessment")
        ai_fallback_result = self._try_ai_services_fallback(environment)
        if ai_fallback_result:
            return ai_fallback_result
        
        # Environment failure: Continue WITHOUT test environment (user's mandate)
        logger.warning(f"🚨 All environment assessment methods failed for: {environment[:100]}{'...' if len(environment) > 100 else ''}")
        logger.warning(f"⚠️ CONTINUING TEST PLANNING WITHOUT TEST ENVIRONMENT")
        return self._create_no_environment_context(environment)
    
    def _determine_acm_status(self, version_info: Dict[str, Any]) -> str:
        """Determine ACM installation status from version info"""
        product = version_info.get('product')
        version = version_info.get('version')
        error = version_info.get('error')
        
        if product == 'ACM' and version and version != 'acm_detected_no_version':
            return 'acm_installed_with_version'
        elif product == 'ACM' and version == 'acm_detected_no_version':
            return 'acm_installed_no_version'
        elif error == 'acm_not_installed':
            return 'acm_not_installed'
        elif error == 'oc_not_available':
            return 'acm_detection_unavailable'
        else:
            return 'acm_status_unknown'
    
    def _try_ai_services_fallback(self, environment: str = None) -> Optional[Dict[str, Any]]:
        """Try AI services fallback when direct environment assessment fails"""
        try:
            logger.info("🤖 Attempting AI services fallback for environment analysis")
            
            # Check if environment string contains useful information for AI analysis
            if not environment or len(environment.strip()) < 10:
                logger.info("❌ Environment string too short for AI analysis")
                return None
            
            # AI analysis of environment string for extracting useful information
            ai_analysis = self._ai_analyze_environment_string(environment)
            
            if ai_analysis and ai_analysis.get('confidence', 0) > 0.7:
                logger.info(f"✅ AI services provided environment analysis with {ai_analysis['confidence']} confidence")
                return {
                    'version': ai_analysis.get('detected_version', 'ai_detected'),
                    'cluster_name': ai_analysis.get('cluster_name', 'ai_extracted'),
                    'api_url': ai_analysis.get('api_url', 'unknown'),
                    'console_url': ai_analysis.get('console_url', 'unknown'),
                    'platform': ai_analysis.get('platform', 'unknown'),
                    'region': ai_analysis.get('region', 'ai_inferred'),
                    'health_status': 'ai_assumed_healthy',
                    'connectivity_confirmed': False,
                    'detection_method': 'ai_services_fallback',
                    'platform_details': ai_analysis.get('platform_details', {}),
                    'tools_available': {'ai_analysis': True},
                    'assessment_timestamp': datetime.now().isoformat(),
                    'api_source': 'ai_services_fallback',
                    'product_detected': ai_analysis.get('product', 'Unknown'),
                    'version_detection_method': 'ai_inference',
                    'acm_status': 'ai_analysis_required',
                    'version_context': {
                        'is_acm': ai_analysis.get('product') == 'ACM',
                        'is_openshift': ai_analysis.get('platform') == 'openshift',
                        'is_kubernetes': ai_analysis.get('platform') == 'kubernetes',
                        'ai_confidence': ai_analysis.get('confidence'),
                        'ai_notes': ai_analysis.get('notes', [])
                    }
                }
            else:
                logger.info("❌ AI services fallback provided low confidence analysis")
                return None
                
        except Exception as e:
            logger.warning(f"AI services fallback failed: {e}")
            return None
    
    def _ai_analyze_environment_string(self, environment: str) -> Optional[Dict[str, Any]]:
        """AI analysis of environment string to extract useful information"""
        try:
            # Simple pattern-based analysis for environment strings
            analysis = {
                'confidence': 0.5,
                'detected_version': 'unknown',
                'platform': 'unknown',
                'notes': []
            }
            
            # Extract cluster name from console URL
            if 'console' in environment.lower():
                import re
                console_match = re.search(r'console[.-]([^/\s:]+)', environment)
                if console_match:
                    analysis['cluster_name'] = console_match.group(1)
                    analysis['console_url'] = environment.split(',')[0].replace('Console: ', '').strip()
                    analysis['confidence'] += 0.2
                    analysis['notes'].append('Extracted cluster info from console URL')
            
            # Detect OpenShift patterns
            if 'openshift' in environment.lower() or 'apps.' in environment:
                analysis['platform'] = 'openshift'
                analysis['product'] = 'OpenShift'
                analysis['confidence'] += 0.1
                analysis['notes'].append('OpenShift patterns detected')
            
            # Extract API URL
            if 'api.' in environment:
                api_match = re.search(r'(https?://api[^/\s:]+:?\d*)', environment)
                if api_match:
                    analysis['api_url'] = api_match.group(1)
                    analysis['confidence'] += 0.1
                    analysis['notes'].append('API URL extracted')
            
            # Check for credential patterns (but don't extract them)
            if 'creds:' in environment.lower() or 'password' in environment.lower():
                analysis['notes'].append('Credentials detected in environment string')
                analysis['confidence'] += 0.05
            
            return analysis if analysis['confidence'] > 0.6 else None
            
        except Exception as e:
            logger.debug(f"AI environment analysis failed: {e}")
            return None
    
    # REMOVED: _get_enhanced_simulated_environment method
    # All environment simulation removed - framework now continues test planning WITHOUT environment
    # when environment assessment fails, using _create_no_environment_context instead
    
    def _calculate_version_gap(self, target_version: str, environment_data: Dict[str, Any]) -> Dict[str, Any]:
        """Calculate version gap between target and environment versions with no-environment handling"""
        
        environment_version = environment_data.get('version', 'unknown')
        environment_product = environment_data.get('product_detected', 'Unknown')
        acm_status = environment_data.get('acm_status', 'unknown')
        version_context = environment_data.get('version_context', {})
        
        # Handle no-environment scenarios
        if environment_version == 'environment_unavailable' or environment_data.get('platform') == 'no_environment':
            logger.warning(f"🚨 No test environment available for version comparison")
            return {
                'comparison': 'no_environment',
                'gap_type': 'environment_unavailable',
                'urgency': 'workflow_completion_without_environment',
                'target_version': target_version,
                'environment_version': None,
                'product_context': {
                    'target_product': 'ACM',
                    'environment_product': 'NO_ENVIRONMENT',
                    'issue': 'No test environment available for version validation',
                    'connection_error': environment_data.get('platform_details', {}).get('error', 'unknown'),
                    'root_cause': environment_data.get('platform_details', {}).get('root_cause', 'unknown')
                },
                'version_difference': {'major': 0, 'minor': 0, 'patch': 0}
            }
        
        def is_acm_version(version_str: str) -> bool:
            """Check if version appears to be ACM version (2.x.x)"""
            try:
                major = int(version_str.split('.')[0])
                return major == 2
            except (ValueError, AttributeError, IndexError):
                return False
        
        def is_openshift_version(version_str: str) -> bool:
            """Check if version appears to be OpenShift version (4.x.x)"""
            try:
                major = int(version_str.split('.')[0])
                return major == 4
            except (ValueError, AttributeError, IndexError):
                return False
        
        def version_to_tuple(version_str: str) -> Tuple[int, ...]:
            """Convert version string to tuple for comparison, handling different formats"""
            try:
                # Handle formats like "4.20.0-ec.4" by taking only the main version part
                base_version = version_str.split('-')[0]
                return tuple(map(int, base_version.split('.')))
            except (ValueError, AttributeError):
                logger.warning(f"Invalid version format: {version_str}")
                return (0, 0, 0)
        
        # Detect product context using enhanced environment data
        target_is_acm = is_acm_version(target_version)
        
        # Use enhanced product detection
        env_is_acm = (environment_product == 'ACM' or 
                     version_context.get('is_acm', False) or
                     acm_status in ['acm_installed_with_version', 'acm_installed_no_version'])
        
        env_is_openshift = (environment_product == 'OpenShift' or 
                           version_context.get('is_openshift', False) or
                           is_openshift_version(environment_version))
        
        # Enhanced ACM status handling
        if target_is_acm:
            logger.info(f"Target is ACM {target_version}, Environment ACM Status: {acm_status}")
            
            if acm_status == 'acm_installed_with_version':
                logger.info(f"✅ ACM version match: Target {target_version} vs Environment {environment_version}")
                # Proceed with normal ACM version comparison
                pass
            elif acm_status == 'acm_installed_no_version':
                logger.warning(f"⚠️ ACM detected but version unavailable")
                return {
                    'comparison': 'acm_version_unavailable',
                    'gap_type': 'version_detection_failed',
                    'urgency': 'medium',
                    'target_version': target_version,
                    'environment_version': environment_version,
                    'product_context': {
                        'target_product': 'ACM',
                        'environment_product': 'ACM',
                        'issue': 'ACM installed but version not detectable',
                        'acm_status': acm_status,
                        'detection_method': environment_data.get('version_detection_method')
                    },
                    'version_difference': {'major': 0, 'minor': 0, 'patch': 0}
                }
            elif acm_status == 'acm_not_installed':
                logger.info(f"❌ ACM not installed in environment")
                return {
                    'comparison': 'not_installed',
                    'gap_type': 'fresh_install_required',
                    'urgency': 'install_required',
                    'target_version': target_version,
                    'environment_version': None,
                    'product_context': {
                        'target_product': 'ACM',
                        'environment_product': environment_product,
                        'issue': 'ACM not installed in environment',
                        'acm_status': acm_status
                    },
                    'version_difference': {'major': 0, 'minor': 0, 'patch': 0}
                }
            elif acm_status == 'acm_detection_unavailable':
                logger.warning(f"⚠️ ACM detection not possible")
                return {
                    'comparison': 'detection_unavailable',
                    'gap_type': 'acm_detection_required',
                    'urgency': 'medium',
                    'target_version': target_version,
                    'environment_version': environment_version,
                    'product_context': {
                        'target_product': 'ACM',
                        'environment_product': environment_product,
                        'issue': 'ACM detection tools not available',
                        'acm_status': acm_status
                    },
                    'version_difference': {'major': 0, 'minor': 0, 'patch': 0}
                }
            elif env_is_openshift and not env_is_acm:
                logger.warning(f"🚨 Context mismatch: Target ACM {target_version} vs Environment OpenShift {environment_version}")
                return {
                    'comparison': 'context_mismatch',
                    'gap_type': 'acm_not_detected',
                    'urgency': 'install_required',
                    'target_version': target_version,
                    'environment_version': environment_version,
                    'product_context': {
                        'target_product': 'ACM',
                        'environment_product': environment_product,
                        'issue': 'ACM version not detected in OpenShift environment',
                        'acm_status': acm_status,
                        'command_used': version_context.get('command_used')
                    },
                    'version_difference': {'major': 0, 'minor': 0, 'patch': 0}
                }
        
        # Normal version comparison (same product context)
        target_tuple = version_to_tuple(target_version)
        env_tuple = version_to_tuple(environment_version)
        
        if target_tuple > env_tuple:
            comparison = "newer"
            gap_type = "upgrade_required"
            urgency = "high" if (target_tuple[0] > env_tuple[0]) else "medium"
        elif target_tuple == env_tuple:
            comparison = "same"
            gap_type = "no_action_needed"
            urgency = "low"
        else:
            comparison = "older"
            gap_type = "downgrade_requested"
            urgency = "review_required"
        
        return {
            'comparison': comparison,
            'gap_type': gap_type,
            'urgency': urgency,
            'target_version': target_version,
            'environment_version': environment_version,
            'product_context': {
                'target_product': 'ACM' if target_is_acm else 'Unknown',
                'environment_product': 'ACM' if env_is_acm else ('OpenShift' if env_is_openshift else 'Unknown'),
                'compatible': True
            },
            'version_difference': {
                'major': target_tuple[0] - env_tuple[0] if len(target_tuple) > 0 and len(env_tuple) > 0 else 0,
                'minor': target_tuple[1] - env_tuple[1] if len(target_tuple) > 1 and len(env_tuple) > 1 else 0,
                'patch': target_tuple[2] - env_tuple[2] if len(target_tuple) > 2 and len(env_tuple) > 2 else 0
            }
        }
    
    def _generate_deployment_instruction(self, target_version: str, environment_version: str, 
                                       gap_analysis: Dict[str, Any]) -> str:
        """Generate deployment instruction based on version gap analysis with product context awareness"""
        
        comparison = gap_analysis['comparison']
        gap_type = gap_analysis['gap_type']
        urgency = gap_analysis['urgency']
        
        # Handle no-environment scenarios
        if comparison == "no_environment":
            product_context = gap_analysis.get('product_context', {})
            connection_error = product_context.get('connection_error', 'unknown')
            root_cause = product_context.get('root_cause', 'unknown')
            
            return (f"NO TEST ENVIRONMENT AVAILABLE: Cannot validate ACM {target_version} deployment - "
                   f"no test environment connection established. Error: {connection_error}. "
                   f"Root cause: {root_cause}. Framework will complete analysis without environment validation.")
        
        # Handle new context mismatch scenarios (from real data testing fixes)
        elif comparison == "context_mismatch":
            product_context = gap_analysis.get('product_context', {})
            target_product = product_context.get('target_product', 'Unknown')
            env_product = product_context.get('environment_product', 'Unknown')
            issue = product_context.get('issue', 'Version context mismatch')
            
            return (f"VERSION CONTEXT MISMATCH: Target {target_product} {target_version} cannot be compared "
                   f"with {env_product} {environment_version}. {issue}. "
                   f"ACM version detection required in OpenShift environment.")
        
        elif comparison == "not_installed":
            return (f"ACM NOT INSTALLED: Install ACM {target_version} in the OpenShift environment. "
                   f"ACM version not detected - fresh installation required.")
        
        elif comparison == "newer":
            if gap_analysis['version_difference']['major'] > 0:
                return (f"MAJOR UPGRADE REQUIRED: Upgrade ACM from {environment_version} to {target_version}. "
                       f"Review breaking changes and perform comprehensive testing.")
            elif gap_analysis['version_difference']['minor'] > 0:
                return (f"MINOR UPGRADE REQUIRED: Upgrade ACM from {environment_version} to {target_version}. "
                       f"Standard upgrade process with feature validation.")
            else:
                return (f"PATCH UPGRADE REQUIRED: Upgrade ACM from {environment_version} to {target_version}. "
                       f"Low-risk patch update recommended.")
        
        elif comparison == "same":
            return (f"NO ACTION REQUIRED: ACM environment is already at target version {target_version}. "
                   f"Proceed with feature testing and validation.")
        
        else:  # older
            return (f"VERSION REVIEW REQUIRED: Target ACM version {target_version} is older than "
                   f"environment version {environment_version}. Review requirements and confirm "
                   f"if downgrade is intentional.")
    
    def _build_foundation_context(self, jira_data: Dict[str, Any], target_version: str,
                                environment_data: Dict[str, Any], gap_analysis: Dict[str, Any],
                                deployment_instruction: str) -> FoundationContext:
        """Build complete foundation context"""
        
        builder = FoundationContextBuilder()
        
        context = (builder
                  .with_jira_info(
                      jira_id=jira_data.get('id', 'UNKNOWN'),
                      title=jira_data.get('title', 'Unknown Title'),
                      status=jira_data.get('status', 'Unknown'),
                      fix_version=jira_data.get('fix_version'),
                      priority=jira_data.get('priority', 'Medium'),
                      component=jira_data.get('component', 'Unknown')
                  )
                  .with_version_context(
                      target_version=target_version,
                      environment_version=environment_data['version'],
                      comparison_result=gap_analysis['comparison'],
                      detection_method=environment_data['detection_method']
                  )
                  .with_environment_baseline(
                      cluster_name=environment_data['cluster_name'],
                      api_url=environment_data['api_url'],
                      console_url=environment_data['console_url'],
                      platform=environment_data['platform'],
                      region=environment_data['region'],
                      health_status=environment_data['health_status'],
                      connectivity_confirmed=environment_data['connectivity_confirmed'],
                      jenkins_deployment_metadata=environment_data.get('raw_data', {}).get('jenkins_deployment_metadata')
                  )
                  .with_deployment_instruction(deployment_instruction)
                  .build())
        
        # Add gap analysis details
        context.version_context.version_gap_details = gap_analysis
        
        return context
    
    def create_foundation_context(self, jira_id: str, environment: str = None,
                                output_file: str = None) -> FoundationContext:
        """
        Create foundation context and optionally save to file
        This is the main public interface for Phase 0
        """
        logger.info(f"Creating foundation context for {jira_id}")
        
        # Perform analysis
        foundation_context = self.analyze_version_gap(jira_id, environment)
        
        # Save to file if requested
        if output_file:
            success = foundation_context.save_to_file(output_file)
            if success:
                logger.info(f"Foundation context saved to {output_file}")
            else:
                logger.error(f"Failed to save foundation context to {output_file}")
        
        # Auto-save to runs directory
        self._auto_save_context(foundation_context, jira_id)
        
        return foundation_context
    
    def _is_valid_version_format(self, version: str) -> bool:
        """Check if version format is valid for various product versions"""
        if not version:
            return False
        
        import re
        # Support various version formats: 
        # - X.Y.Z (standard semver)
        # - X.Y.Z-suffix (e.g., 4.20.0-ec.4, 2.15.0-RC1)
        # - X.Y.Z.suffix (alternative format)
        pattern = r'^\d+\.\d+\.\d+(-[a-zA-Z0-9.-]+)*$'
        return bool(re.match(pattern, str(version)))
    
    def _auto_save_context(self, context: FoundationContext, jira_id: str):
        """Automatically save context to runs directory with proper structure"""
        try:
            # Create JIRA-specific run directory
            timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
            run_dir = os.path.join(self.runs_dir, jira_id, f"{jira_id}-{timestamp}")
            
            # Ensure directory exists
            os.makedirs(run_dir, exist_ok=True)
            
            # Save foundation context
            context_file = os.path.join(run_dir, "foundation-context.json")
            context.save_to_file(context_file)
            
            # Update latest symlink
            latest_link = os.path.join(self.runs_dir, jira_id, "latest")
            if os.path.lexists(latest_link):
                os.unlink(latest_link)
            os.symlink(f"{jira_id}-{timestamp}", latest_link)
            
            logger.info(f"Foundation context auto-saved to {run_dir}")
            
        except Exception as e:
            logger.warning(f"Auto-save failed: {e}")
    
    def validate_foundation_context(self, context: FoundationContext) -> bool:
        """Validate foundation context completeness and quality"""
        validation_results = context.validate_completeness()
        
        # Log validation results
        logger.info("Foundation context validation:")
        for check, result in validation_results.items():
            status = "✅" if result else "❌"
            logger.info(f"  {status} {check}: {result}")
        
        # Check if ready for agent inheritance
        ready = context.is_ready_for_agent_inheritance()
        logger.info(f"Ready for agent inheritance: {'✅' if ready else '❌'}")
        
        return ready
    
    def get_foundation_context_summary(self, context: FoundationContext) -> Dict[str, Any]:
        """Get human-readable summary of foundation context"""
        return {
            'phase_0_summary': {
                'jira_ticket': f"{context.jira_info.jira_id}: {context.jira_info.title}",
                'version_analysis': {
                    'target': context.version_context.target_version,
                    'environment': context.version_context.environment_version,
                    'gap': context.version_context.comparison_result,
                    'action_needed': context.deployment_instruction
                },
                'environment_status': {
                    'cluster': context.environment_baseline.cluster_name,
                    'health': context.environment_baseline.health_status,
                    'connectivity': context.environment_baseline.connectivity_confirmed
                },
                'readiness': {
                    'agent_inheritance_ready': context.agent_inheritance_ready,
                    'validation_score': context.metadata.consistency_score,
                    'created': context.metadata.creation_timestamp
                }
            }
        }


# Convenience functions for external use
def create_phase_0_context(jira_id: str, environment: str = None) -> FoundationContext:
    """Convenience function to create Phase 0 foundation context"""
    service = VersionIntelligenceService()
    return service.create_foundation_context(jira_id, environment)


def analyze_jira_ticket(jira_id: str, environment: str = None, 
                       output_file: str = None) -> Dict[str, Any]:
    """Analyze JIRA ticket and return comprehensive results"""
    service = VersionIntelligenceService()
    context = service.create_foundation_context(jira_id, environment, output_file)
    return service.get_foundation_context_summary(context)


# Module-level functions for test compatibility
def execute_phase_0(jira_id: str, environment: str = None) -> FoundationContext:
    """
    Execute Phase 0 - Main entry point for Version Intelligence analysis
    Creates complete foundation context for JIRA ticket and environment
    
    Args:
        jira_id: JIRA ticket identifier (e.g., 'ACM-22079')
        environment: Target environment name (optional)
        
    Returns:
        FoundationContext: Complete foundation context ready for agent inheritance
        
    Raises:
        VersionIntelligenceError: If analysis fails
    """
    logger.info(f"🚀 Executing Phase 0 for {jira_id}")
    
    try:
        service = VersionIntelligenceService()
        foundation_context = service.analyze_version_gap(jira_id, environment)
        
        # Validate readiness for agent inheritance
        if not foundation_context.is_ready_for_agent_inheritance():
            raise VersionIntelligenceError(
                f"Phase 0 failed - Foundation context not ready for agent inheritance: "
                f"{foundation_context.validation_results}"
            )
        
        logger.info(f"✅ Phase 0 completed successfully for {jira_id}")
        return foundation_context
        
    except Exception as e:
        logger.error(f"❌ Phase 0 execution failed for {jira_id}: {str(e)}")
        raise VersionIntelligenceError(f"Phase 0 execution failed: {str(e)}") from e


def execute_phase_0_with_output(jira_id: str, environment: str, output_dir: str) -> Dict[str, Any]:
    """
    Execute Phase 0 with file output generation
    Creates foundation context and saves all output files to specified directory
    
    Args:
        jira_id: JIRA ticket identifier
        environment: Target environment name  
        output_dir: Directory to save output files
        
    Returns:
        Dict containing foundation context data and file paths
        
    Raises:
        VersionIntelligenceError: If execution or file generation fails
    """
    logger.info(f"🚀 Executing Phase 0 with output for {jira_id} → {output_dir}")
    
    try:
        # Execute Phase 0 analysis
        foundation_context = execute_phase_0(jira_id, environment)
        
        # Ensure output directory exists
        os.makedirs(output_dir, exist_ok=True)
        
        # Save foundation context to file
        foundation_context_file = os.path.join(output_dir, 'foundation-context.json')
        success = foundation_context.save_to_file(foundation_context_file)
        
        if not success:
            raise VersionIntelligenceError(f"Failed to save foundation context to {foundation_context_file}")
        
        # Create summary data for return
        context_data = {
            'jira_id': foundation_context.jira_info.jira_id,
            'target_version': foundation_context.version_context.target_version,
            'environment_version': foundation_context.version_context.environment_version,
            'version_gap': foundation_context.version_context.comparison_result,
            'environment': foundation_context.environment_baseline.cluster_name,
            'deployment_instruction': foundation_context.deployment_instruction,
            'deployment_status': 'Feature not yet available' if foundation_context.version_context.comparison_result == 'newer' else 'Feature deployed',
            'output_files': {
                'foundation_context': foundation_context_file
            }
        }
        
        logger.info(f"✅ Phase 0 with output completed successfully for {jira_id}")
        return context_data
        
    except Exception as e:
        logger.error(f"❌ Phase 0 with output failed for {jira_id}: {str(e)}")
        raise VersionIntelligenceError(f"Phase 0 with output failed: {str(e)}") from e


def analyze_version_gap(target_version: str, environment_version: str) -> Dict[str, Any]:
    """
    Module-level wrapper for version gap analysis
    Analyzes version differences and provides deployment guidance
    
    Args:
        target_version: Target version string (e.g., '2.15.0')
        environment_version: Current environment version string (e.g., '2.14.0')
        
    Returns:
        Dict containing version gap analysis results
    """
    logger.info(f"🔍 Analyzing version gap: {environment_version} → {target_version}")
    
    try:
        service = VersionIntelligenceService()
        gap_analysis = service._calculate_version_gap(target_version, environment_version)
        deployment_instruction = service._generate_deployment_instruction(
            target_version, environment_version, gap_analysis
        )
        
        return {
            'version_gap': gap_analysis['comparison'],
            'deployment_instruction': deployment_instruction,
            'gap_details': gap_analysis,
            'target_version': target_version,
            'environment_version': environment_version
        }
        
    except Exception as e:
        logger.error(f"❌ Version gap analysis failed: {str(e)}")
        raise VersionIntelligenceError(f"Version gap analysis failed: {str(e)}") from e


def create_foundation_context(jira_id: str, environment: str = None) -> FoundationContext:
    """
    Module-level wrapper for foundation context creation
    Creates complete foundation context for JIRA ticket
    
    Args:
        jira_id: JIRA ticket identifier
        environment: Target environment name (optional)
        
    Returns:
        FoundationContext: Complete foundation context
    """
    logger.info(f"🏗️ Creating foundation context for {jira_id}")
    
    try:
        service = VersionIntelligenceService()
        return service.create_foundation_context(jira_id, environment)
        
    except Exception as e:
        logger.error(f"❌ Foundation context creation failed for {jira_id}: {str(e)}")
        raise VersionIntelligenceError(f"Foundation context creation failed: {str(e)}") from e


    def _raise_jira_failure(self, jira_id: str, error_details: str):
        """Raise detailed JIRA failure - stops framework completely"""
        
        suggestions = [
            f"1. Check JIRA connectivity: Verify access to https://issues.redhat.com/browse/{jira_id}",
            "2. Verify JIRA CLI setup: Run 'jira version' to check CLI installation",
            "3. Check JIRA authentication: Ensure JIRA_API_TOKEN environment variable is set",
            "4. Verify ticket existence: Confirm the JIRA ticket ID is correct and accessible",
            "5. Check network connectivity: Ensure access to Red Hat JIRA instance",
            "6. Try WebFetch fallback: Check if browser access to JIRA works"
        ]
        
        # Log failure details for debugging
        logger.error(f"🚨 FRAMEWORK STOPPED: JIRA extraction failed for {jira_id}")
        logger.error(f"   Error: {error_details}")
        logger.error(f"   Actionable suggestions:")
        for suggestion in suggestions:
            logger.error(f"   {suggestion}")
        
        raise JIRAExtractionError(error_details, jira_id, suggestions)
    
    def _create_no_environment_context(self, environment: str) -> Dict[str, Any]:
        """Create no-environment context for continuing test planning without cluster"""
        
        logger.warning(f"📋 Creating NO-ENVIRONMENT context for test planning")
        logger.warning(f"   Target environment: {environment[:80]}{'...' if len(environment) > 80 else ''}")
        logger.warning(f"   Test cases will include environment setup instructions")
        logger.warning(f"   Manual cluster verification will be required")
        
        return {
            'version': 'NO_ENVIRONMENT',
            'cluster_name': 'test-environment-required',
            'api_url': 'manual-setup-required',
            'console_url': 'manual-setup-required', 
            'platform': 'environment-independent',
            'region': 'not-applicable',
            'health_status': 'unavailable',
            'connectivity_confirmed': False,
            'detection_method': 'no_environment_fallback',
            'platform_details': {
                'platform': 'requires-manual-setup',
                'distribution': 'any-kubernetes-openshift',
                'features': ['manual-verification-required'],
                'setup_required': True
            },
            'tools_available': [],
            'assessment_timestamp': datetime.now().isoformat(),
            'api_source': 'no_environment_fallback',
            'test_planning_mode': 'environment_independent',
            'manual_setup_required': True,
            'original_target': environment,
            'framework_continuation': 'test_planning_without_environment'
        }


if __name__ == "__main__":
    # Example usage for testing
    import sys
    
    if len(sys.argv) > 1:
        jira_id = sys.argv[1]
        environment = sys.argv[2] if len(sys.argv) > 2 else None
        
        print(f"🚀 Analyzing {jira_id}...")
        try:
            results = analyze_jira_ticket(jira_id, environment)
            print("✅ Analysis completed successfully!")
            print(json.dumps(results, indent=2))
        except Exception as e:
            print(f"❌ Analysis failed: {e}")
            sys.exit(1)
    else:
        print("Usage: python version_intelligence_service.py <JIRA_ID> [environment]")
        sys.exit(1)