#!/usr/bin/env python3
"""
Unit Tests for QE Intelligence Service - Strategic Recommendations Generation (Chunk 5)
====================================================================================

Comprehensive unit tests specifically for the strategic recommendations generation implementation.
Tests business intelligence, customer alignment, and implementation guidance components.
"""

import unittest
import os
import sys
from unittest.mock import Mock, patch
from typing import Dict, Any, List

# Import path setup
def setup_test_paths():
    """Set up import paths for testing environment"""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.join(current_dir, '..', '..', '..')
    ai_services_path = os.path.join(project_root, '.claude', 'ai-services')
    
    if ai_services_path not in sys.path:
        sys.path.insert(0, ai_services_path)
    
    return ai_services_path

setup_test_paths()

try:
    from qe_intelligence_service import QEIntelligenceService, QEIntelligenceResult
    IMPLEMENTATION_AVAILABLE = True
    print("âœ… QE Intelligence Service implementation found for strategic recommendations testing")
except ImportError as e:
    print(f"âŒ QE Intelligence Service implementation not available: {e}")
    IMPLEMENTATION_AVAILABLE = False


class TestQEStrategicRecommendations(unittest.TestCase):
    """Unit tests for QE Intelligence Service strategic recommendations functionality"""
    
    @classmethod
    def setUpClass(cls):
        """Set up test environment"""
        if not IMPLEMENTATION_AVAILABLE:
            cls.skipTest(cls, "QE Intelligence Service implementation not available")
    
    def setUp(self):
        """Set up each test"""
        self.qe_service = QEIntelligenceService()
        
        # Test gap analysis data for recommendations
        self.test_gaps = {
            'identified_gaps': {
                'critical_gaps': [
                    {
                        'area': 'disconnected_environment_simulation',
                        'current_coverage': 20.0,
                        'priority_score': 130,
                        'customer_impact': 'amadeus_requirement',
                        'gap_severity': 'high'
                    },
                    {
                        'area': 'three_tier_fallback_edge_cases',
                        'current_coverage': 30.0,
                        'priority_score': 120,
                        'customer_impact': 'reliability_assurance',
                        'gap_severity': 'high'
                    }
                ],
                'high_gaps': [
                    {
                        'area': 'security_coverage',
                        'current_coverage': 40.0,
                        'priority_score': 90,
                        'customer_impact': 'enterprise_compliance',
                        'gap_severity': 'medium'
                    }
                ]
            },
            'gap_calculation_details': {
                'critical_gap_percentage': 6.5,
                'high_gap_percentage': 4.7,
                'total_calculated_gap': 18.8
            },
            'customer_alignment_assessment': {
                'amadeus_alignment_score': 0.5,
                'disconnected_environment_coverage': True,
                'requirement_satisfaction_outlook': 'good_satisfaction_with_gap_resolution'
            },
            'evidence_traceability': {
                'repository_evidence': {'evidence_quality': 'high'},
                'pattern_evidence': ['pattern1', 'pattern2'],
                'customer_evidence': ['agent_a_jira_analysis']
            }
        }
    
    def test_generate_immediate_action_recommendations(self):
        """Test immediate action recommendations generation"""
        recommendations = self.qe_service._generate_strategic_recommendations(self.test_gaps)
        immediate_actions = recommendations['immediate_actions']
        
        # Verify immediate actions structure
        self.assertIsInstance(immediate_actions, list)
        self.assertGreater(len(immediate_actions), 0)
        self.assertLessEqual(len(immediate_actions), 5)  # Limited to top 5
        
        # Verify action structure
        for action in immediate_actions:
            required_fields = [
                'action', 'description', 'priority', 'priority_score',
                'timeline', 'effort_estimate', 'coverage_impact',
                'customer_value', 'implementation_steps', 'business_justification'
            ]
            for field in required_fields:
                self.assertIn(field, action)
        
        # Verify priority sorting (highest score first)
        if len(immediate_actions) > 1:
            self.assertGreaterEqual(
                immediate_actions[0]['priority_score'],
                immediate_actions[1]['priority_score']
            )
    
    def test_create_immediate_action(self):
        """Test immediate action creation from gaps"""
        test_gap = {
            'area': 'disconnected_environment_simulation',
            'current_coverage': 20.0,
            'customer_impact': 'amadeus_requirement',
            'gap_severity': 'high'
        }
        
        action = self.qe_service._create_immediate_action(test_gap, 'critical')
        
        # Verify action structure
        self.assertEqual(action['action'], 'implement_disconnected_environment_test_suite')
        self.assertEqual(action['priority'], 'critical')
        self.assertIn('amadeus', action['customer_value'])
        self.assertEqual(action['timeline'], '1_week')
        self.assertIsInstance(action['implementation_steps'], list)
        self.assertGreater(len(action['implementation_steps']), 0)
        
        # Verify priority scoring with Amadeus bonus
        self.assertGreaterEqual(action['priority_score'], 120)  # Base 100 + Amadeus bonus 20
    
    def test_generate_strategic_initiative_recommendations(self):
        """Test strategic initiative recommendations generation"""
        recommendations = self.qe_service._generate_strategic_recommendations(self.test_gaps)
        strategic_initiatives = recommendations['strategic_initiatives']
        
        # Verify strategic initiatives structure
        self.assertIsInstance(strategic_initiatives, list)
        self.assertGreater(len(strategic_initiatives), 0)
        
        # Verify initiative structure
        for initiative in strategic_initiatives:
            required_fields = [
                'initiative', 'description', 'strategic_value',
                'timeline', 'effort_estimate', 'coverage_improvement',
                'implementation_phases', 'business_impact', 'success_metrics'
            ]
            for field in required_fields:
                self.assertIn(field, initiative)
        
        # Check for Amadeus-specific initiative when alignment is low
        amadeus_initiative = next(
            (init for init in strategic_initiatives if 'amadeus' in init['initiative']), 
            None
        )
        self.assertIsNotNone(amadeus_initiative, "Should include Amadeus initiative when alignment < 0.8")
    
    def test_generate_optimization_recommendations(self):
        """Test optimization recommendations generation"""
        recommendations = self.qe_service._generate_strategic_recommendations(self.test_gaps)
        optimization = recommendations['optimization_recommendations']
        
        # Verify optimization structure
        expected_categories = [
            'test_automation_optimization',
            'pattern_standardization', 
            'customer_feedback_integration'
        ]
        
        for category in expected_categories:
            self.assertIn(category, optimization)
            self.assertIn('description', optimization[category])
            self.assertIn('recommendations', optimization[category])
            self.assertIn('expected_impact', optimization[category])
    
    def test_generate_implementation_guidance(self):
        """Test implementation guidance generation"""
        # Create mock immediate actions and strategic initiatives
        mock_immediate_actions = [
            {'action': 'action1', 'timeline': '1_week', 'effort_estimate': '3-5_engineer_days'},
            {'action': 'action2', 'timeline': '2_weeks', 'effort_estimate': '4-6_engineer_days'}
        ]
        mock_strategic_initiatives = [
            {'initiative': 'init1', 'timeline': '3-4_weeks', 'effort_estimate': '15-20_engineer_days'},
            {'initiative': 'init2', 'timeline': '6-8_weeks', 'effort_estimate': '25-30_engineer_days'}
        ]
        
        guidance = self.qe_service._generate_implementation_guidance(
            mock_immediate_actions, mock_strategic_initiatives
        )
        
        # Verify guidance structure
        expected_sections = [
            'implementation_sequence',
            'resource_requirements',
            'success_tracking',
            'risk_management'
        ]
        
        for section in expected_sections:
            self.assertIn(section, guidance)
        
        # Verify implementation sequence
        sequence = guidance['implementation_sequence']
        self.assertIn('week_1', sequence)
        self.assertIn('week_2', sequence)
        self.assertIn('month_1', sequence)
        self.assertIn('quarter_1', sequence)
        
        # Verify resource requirements calculation
        resources = guidance['resource_requirements']
        self.assertIn('total_engineer_days', resources)
        self.assertGreater(resources['total_engineer_days'], 0)
    
    def test_calculate_business_impact_assessment(self):
        """Test business impact assessment calculation"""
        mock_immediate_actions = [
            {'coverage_impact': 5.2},
            {'coverage_impact': 4.7}
        ]
        mock_strategic_initiatives = [
            {'coverage_improvement': 12.5},
            {'coverage_improvement': 15.0}
        ]
        
        impact = self.qe_service._calculate_business_impact_assessment(
            mock_immediate_actions, mock_strategic_initiatives
        )
        
        # Verify impact assessment structure
        expected_sections = [
            'total_coverage_improvement',
            'immediate_impact',
            'strategic_impact',
            'customer_impact',
            'operational_impact',
            'financial_impact'
        ]
        
        for section in expected_sections:
            self.assertIn(section, impact)
        
        # Verify total calculation
        expected_total = 5.2 + 4.7 + 12.5 + 15.0
        self.assertAlmostEqual(impact['total_coverage_improvement'], expected_total, places=1)
    
    def test_generate_customer_success_metrics(self):
        """Test customer success metrics generation"""
        recommendations = self.qe_service._generate_strategic_recommendations(self.test_gaps)
        success_metrics = recommendations['customer_success_metrics']
        
        # Verify success metrics structure
        expected_categories = [
            'amadeus_success_metrics',
            'enterprise_confidence_metrics',
            'quality_evolution_metrics',
            'tracking_framework'
        ]
        
        for category in expected_categories:
            self.assertIn(category, success_metrics)
        
        # Verify Amadeus-specific metrics
        amadeus_metrics = success_metrics['amadeus_success_metrics']
        self.assertIn('disconnected_environment_readiness', amadeus_metrics)
        self.assertIn('partnership_health_score', amadeus_metrics)
    
    def test_calculate_recommendation_confidence(self):
        """Test recommendation confidence calculation"""
        confidence = self.qe_service._calculate_recommendation_confidence(self.test_gaps)
        
        # Verify confidence is valid float between 0 and 1
        self.assertIsInstance(confidence, float)
        self.assertGreaterEqual(confidence, 0.0)
        self.assertLessEqual(confidence, 1.0)
        
        # Verify confidence calculation factors
        # Should be reasonable given test data
        self.assertGreater(confidence, 0.3)  # Should have reasonable confidence
    
    def test_action_business_justification(self):
        """Test action business justification generation"""
        test_gap = {'area': 'test', 'customer_impact': 'amadeus_requirement'}
        
        justification = self.qe_service._generate_action_business_justification(
            test_gap, 'amadeus_requirement'
        )
        
        # Verify Amadeus requirement gets critical justification
        self.assertIn('CRITICAL', justification)
        self.assertIn('Amadeus', justification)
    
    def test_action_success_criteria(self):
        """Test action success criteria generation"""
        criteria = self.qe_service._generate_action_success_criteria(
            'disconnected_environment_simulation', 'amadeus_requirement'
        )
        
        # Verify criteria structure
        self.assertIsInstance(criteria, list)
        self.assertGreater(len(criteria), 0)
        
        # Verify disconnected environment specific criteria
        criteria_text = ' '.join(criteria).lower()
        self.assertIn('disconnected', criteria_text)
        self.assertIn('amadeus', criteria_text)
    
    def test_action_risk_mitigation(self):
        """Test action risk mitigation generation"""
        mitigation = self.qe_service._generate_action_risk_mitigation('test_area')
        
        # Verify risk mitigation structure
        self.assertIsInstance(mitigation, list)
        self.assertGreater(len(mitigation), 0)
        
        # Verify contains incremental implementation strategy
        mitigation_text = ' '.join(mitigation).lower()
        self.assertIn('incremental', mitigation_text)
    
    def test_end_to_end_strategic_recommendations(self):
        """Test complete end-to-end strategic recommendations generation"""
        # Execute complete QE analysis to test recommendations integration
        test_context = {
            'agent_contributions': {
                'agent_a_jira': {
                    'customer_requirements': {
                        'amadeus_disconnected_env': True,
                        'three_tier_fallback': True
                    }
                }
            }
        }
        
        result = self.qe_service.execute_qe_analysis(test_context)
        recommendations = result.strategic_recommendations
        
        # Verify complete recommendations structure
        required_sections = [
            'immediate_actions',
            'strategic_initiatives',
            'optimization_recommendations',
            'implementation_guidance',
            'business_impact_assessment',
            'customer_success_metrics',
            'evidence_traceability',
            'recommendation_metadata'
        ]
        
        for section in required_sections:
            self.assertIn(section, recommendations)
        
        # Verify metadata
        metadata = recommendations['recommendation_metadata']
        self.assertEqual(metadata['generation_method'], 'evidence_based_business_intelligence')
        self.assertEqual(metadata['customer_focus'], 'amadeus_disconnected_environment_priority')
        self.assertIsInstance(metadata['confidence_level'], float)
    
    def test_amadeus_priority_alignment(self):
        """Test Amadeus customer priority alignment in recommendations"""
        recommendations = self.qe_service._generate_strategic_recommendations(self.test_gaps)
        
        # Verify Amadeus gap gets highest priority
        immediate_actions = recommendations['immediate_actions']
        if immediate_actions:
            top_action = immediate_actions[0]
            
            # Check if disconnected environment (Amadeus requirement) is prioritized
            if 'disconnected' in top_action.get('action', ''):
                self.assertIn('amadeus', top_action.get('customer_value', '').lower())
    
    def test_recommendation_traceability(self):
        """Test recommendation evidence traceability"""
        recommendations = self.qe_service._generate_strategic_recommendations(self.test_gaps)
        traceability = recommendations['evidence_traceability']
        
        # Verify traceability includes all agent sources
        expected_sources = [
            'requirements_source',
            'implementation_source',
            'environment_source',
            'documentation_source',
            'gap_analysis_source',
            'business_intelligence_source'
        ]
        
        for source in expected_sources:
            self.assertIn(source, traceability)
            self.assertIsInstance(traceability[source], str)


class TestStrategicRecommendationsEdgeCases(unittest.TestCase):
    """Test edge cases and error conditions for strategic recommendations"""
    
    def setUp(self):
        """Set up each test"""
        if not IMPLEMENTATION_AVAILABLE:
            self.skipTest("QE Intelligence Service implementation not available")
        
        self.qe_service = QEIntelligenceService()
    
    def test_empty_gaps_handling(self):
        """Test strategic recommendations with empty gaps"""
        empty_gaps = {
            'identified_gaps': {
                'critical_gaps': [],
                'high_gaps': [],
                'medium_gaps': [],
                'low_gaps': []
            },
            'gap_calculation_details': {
                'total_calculated_gap': 0.0
            },
            'customer_alignment_assessment': {}
        }
        
        recommendations = self.qe_service._generate_strategic_recommendations(empty_gaps)
        
        # Should still generate valid structure even with no gaps
        self.assertIn('immediate_actions', recommendations)
        self.assertIn('strategic_initiatives', recommendations)
        self.assertIsInstance(recommendations['immediate_actions'], list)
    
    def test_minimal_gap_data_handling(self):
        """Test strategic recommendations with minimal gap data"""
        minimal_gaps = {
            'identified_gaps': {
                'critical_gaps': [{'area': 'test_gap'}]
            }
        }
        
        recommendations = self.qe_service._generate_strategic_recommendations(minimal_gaps)
        
        # Should handle minimal data gracefully
        self.assertIsNotNone(recommendations)
        self.assertIn('immediate_actions', recommendations)
    
    def test_high_amadeus_alignment_scenario(self):
        """Test recommendations when Amadeus alignment is already high"""
        high_alignment_gaps = {
            'identified_gaps': {'critical_gaps': [], 'high_gaps': []},
            'customer_alignment_assessment': {
                'amadeus_alignment_score': 0.9  # High alignment
            }
        }
        
        recommendations = self.qe_service._generate_strategic_recommendations(high_alignment_gaps)
        strategic_initiatives = recommendations['strategic_initiatives']
        
        # Should not include Amadeus-specific initiative when alignment is already high
        amadeus_initiative = next(
            (init for init in strategic_initiatives if 'amadeus' in init.get('initiative', '')), 
            None
        )
        # Note: This may still exist as the test includes other initiatives
        self.assertIsNotNone(strategic_initiatives)  # Should have other initiatives


if __name__ == '__main__':
    print("ðŸ§  QE Intelligence Service - Strategic Recommendations Unit Tests")
    print("=" * 80)
    print("Testing Chunk 5 implementation: Business intelligence and strategic recommendations")
    print("ðŸŽ¯ Focus: Action generation, business impact, and customer alignment")
    print("=" * 80)
    
    unittest.main(verbosity=2)