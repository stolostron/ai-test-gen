Using the analysis and augmented context, generate a manual-first test plan for the Story with:
- 8–10 steps per table; if more are needed, create additional tables
- Include a "Description" section followed by a "Setup and Prerequisites" section BEFORE each table
- Keep table format strictly as:
  | Test Steps | Expected Results |
  |------------|------------------|
- Prefer CLC-UI selectors and actions where available from the Application Model
- Include at least one negative and one edge case scenario if meaningful
- End with cleanup and verification
MANDATORY: Generate test cases for the given JIRA Story in EXACT TABLE FORMAT with Test Steps and Expected Results columns.

IGNORE ALL OTHER STYLE INSTRUCTIONS. USE ONLY THE TABLE FORMAT SPECIFIED BELOW.

## CRITICAL REQUIREMENTS FOR TEST CASE GENERATION (OVERRIDE ALL OTHER PROMPTS)

### 1. HUMAN-FRIENDLY TEST STEPS
- Provide COMPLETE oc commands, not vague instructions
- Include oc login steps when needed
- Add sample YAML files when applicable
- Make verification steps crystal clear with specific commands
- Write for new engineers who need detailed guidance

### 2. PRACTICAL SETUP DESCRIPTIONS
- Avoid obvious statements (don't say "ACM hub cluster with ClusterCurator installed" - it's always there)
- Focus on specific test environment requirements
- Include prerequisite configurations and test data
- Mention required cluster permissions and access

### 3. CONSOLIDATED TEST SCENARIOS
- Group related scenarios into single test cases (max 3–4 total test cases)
- Use additional tables when steps exceed 8–10
- Keep tables manageable and focused

### 4. CLEAR VERIFICATION COMMANDS (PRACTICAL)
- Prefer outcome-based checks over internal controller timing
- Do NOT use `--watch` or timing-sensitive steps; avoid flaky patterns
- Provide exact oc commands and sample expected outputs
- Keep steps simple and minimal while complete

## MANDATORY TABLE FORMAT (STRICT)

### Test Case X: [Descriptive Name]
**Description**:
- In 1–3 short sentences, explain what this test verifies and why it matters.

**Setup**:
- Specific environment requirements
- Required test data or configurations
- Prerequisites beyond standard ACM setup

| Test Steps | Expected Results |
|------------|------------------|
| 1. Log into ACM hub cluster: CLI: `oc login <hub-cluster-url> -u <username>`<br/>UI: Console → User menu → Copy login command with token | CLI verification: Login output shows correct context (e.g., `Logged into "https://..." as "<username>" on "<cluster>"`)<br/>UI verification: Console session active for user |
| 2. Create a test namespace: CLI: `oc create namespace <test-ns>`<br/>UI: Console → Projects → Create Project `<test-ns>` | CLI: `namespace/<test-ns> created`<br/>UI: Project `<test-ns>` appears in the list |
| 3. Apply feature-specific resource (YAML): CLI: `oc apply -f <file>.yaml`<br/>UI: Use wizard/page to create resource | CLI: `<kind>.<group>/<name> created` (show example line)<br/>UI: Resource visible in corresponding UI page |

## GENERATE EXACTLY 3–4 TEST CASES COVERING:
- Core success path(s)
- A negative scenario and/or error handling
- Environment variants (e.g., disconnected, multi-cluster) only if applicable
- RBAC/permissions where meaningful

## OUTPUT REQUIREMENTS

- Generate EXACTLY 3–4 test cases maximum
- Each test case can have multiple scenarios within it
- Always provide complete oc commands with sample expected output
- Include sample YAML configurations
- Make verification steps crystal clear
- Write for engineers who may be new to ACM/OpenShift
- Focus on practical, executable test steps

## MANDATORY FORMAT OVERRIDE

DO NOT GENERATE:
- HTML format
- Complex styling
- Multiple file formats
- Style-matching content

DO GENERATE:
- Simple markdown tables ONLY
- "| Test Steps | Expected Results |" format EXACTLY
- Description and Setup sections BEFORE each table
- Clear, practical test steps
- Each step should include a brief 1–2 line rationale/context in the Expected Results explaining what is validated and why
- For each applicable step, include BOTH variants in the same row:
  - In the "Test Steps" cell, write: `CLI: <command>` then `<br/>UI: <short UI path>` (e.g., `Go to Search page → Enter "Kind:Pod" → Click Search`). If no UI is applicable, write `UI: N/A`.
  - In the "Expected Results" cell, mirror the dual form: `CLI verification: ...` then `<br/>UI verification: ...` (or `UI verification: N/A`).

### Clarity and Simplicity Rules (OVERRIDE)
- Prefer simple, readable commands; avoid complex regex and deeply nested jsonpath.
- Break complex validations into multiple smaller steps (e.g., one step to list, next step to verify value).
- Avoid ambiguous patterns like `grep -E "(cluster-[1-3])"`; state explicit criteria and show an example line of expected output.
- When showing custom-columns/jsonpath, include a short explanation of each column and a sample output line.
- Always provide explicit expected output (example line) when using grep/filters, not just the command.
- Use namespace 'ocm' for hub-controller resources and examples unless clearly stated otherwise.

FINAL INSTRUCTION: Output MUST contain "| Test Steps | Expected Results |" table headers. No exceptions. If you cannot produce a filled plan, output a minimal valid table with 3 executable rows.